{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc574f8e-2e4d-4ea6-bc74-caa9288b29f7",
   "metadata": {},
   "source": [
    "# Ann Arbor Parking Ticket Analysis\n",
    "This analysis explores parking violation patterns in Ann Arbor using data obtained through Freedom of Information Act (FOIA) requests. The dataset spans from 2015 to early 2020, providing comprehensive insights into parking enforcement trends, vehicle distributions, and violation patterns across the city.\n",
    "\n",
    "## Project Objectives\n",
    "1. Extract and consolidate parking ticket data from multiple excel files\n",
    "2. Examine the temporal distribution of different violation types\n",
    "3. Study out-of-state vehicle patterns with a focus on New York registrations\n",
    "4. Investigate Michigan license plate formats and their frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3b376-2f56-40d7-a951-d3682a723840",
   "metadata": {},
   "source": [
    "# 1. Data Processing and Integration\n",
    "## Overview\n",
    "\n",
    "The initial phase involves combining multiple Excel files containing parking ticket records. Each file requires careful handling due to varying sheet structures and header formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7900fe9a-68c2-404f-8d40-db7fe2252476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation-jan2020.xls\n",
      "Combined DataFrame shape: (811439, 14)\n",
      "DataFrame Shape: (811439, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket #</th>\n",
       "      <th>Badge</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>IssueTime</th>\n",
       "      <th>Plate</th>\n",
       "      <th>State</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Violation</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Meter</th>\n",
       "      <th>Fine</th>\n",
       "      <th>Penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H000210594</td>\n",
       "      <td>036</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2214</td>\n",
       "      <td>LAS5658</td>\n",
       "      <td>OH</td>\n",
       "      <td>SUBA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A04</td>\n",
       "      <td>NO PRKNG ANYTME</td>\n",
       "      <td>525 ELM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2100005782</td>\n",
       "      <td>821</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>0824</td>\n",
       "      <td>DEZ4465</td>\n",
       "      <td>MI</td>\n",
       "      <td>FORD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01</td>\n",
       "      <td>EXPIRED METER</td>\n",
       "      <td>600 BLK OF STATE SOU</td>\n",
       "      <td>4006A</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2110008524</td>\n",
       "      <td>826</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1719</td>\n",
       "      <td>DCM1327</td>\n",
       "      <td>MI</td>\n",
       "      <td>SATU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01</td>\n",
       "      <td>EXPIRED METER</td>\n",
       "      <td>FARMER'S MARKET</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2110008525</td>\n",
       "      <td>826</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1725</td>\n",
       "      <td>BAX385</td>\n",
       "      <td>IA</td>\n",
       "      <td>CHEV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01</td>\n",
       "      <td>EXPIRED METER</td>\n",
       "      <td>FARMER'S MARKET</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2100005834</td>\n",
       "      <td>821</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1344</td>\n",
       "      <td>2LEH1</td>\n",
       "      <td>MI</td>\n",
       "      <td>FORD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A04</td>\n",
       "      <td>NO PRKNG ANYTME</td>\n",
       "      <td>600 BLK OF WILLIAM E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticket # Badge           Issue Date IssueTime    Plate State  Make Model  \\\n",
       "0  H000210594   036  2015-01-01 00:00:00      2214  LAS5658    OH  SUBA   NaN   \n",
       "1  2100005782   821  2015-01-02 00:00:00      0824  DEZ4465    MI  FORD   NaN   \n",
       "2  2110008524   826  2015-01-02 00:00:00      1719  DCM1327    MI  SATU   NaN   \n",
       "3  2110008525   826  2015-01-02 00:00:00      1725   BAX385    IA  CHEV   NaN   \n",
       "4  2100005834   821  2015-01-02 00:00:00      1344    2LEH1    MI  FORD   NaN   \n",
       "\n",
       "  Violation      Description              Location  Meter Fine Penalty  \n",
       "0       A04  NO PRKNG ANYTME               525 ELM    NaN   35      20  \n",
       "1       A01    EXPIRED METER  600 BLK OF STATE SOU  4006A   10       0  \n",
       "2       A01    EXPIRED METER       FARMER'S MARKET     17   10       0  \n",
       "3       A01    EXPIRED METER       FARMER'S MARKET     35   10       0  \n",
       "4       A04  NO PRKNG ANYTME  600 BLK OF WILLIAM E    NaN   25       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_ticket_data():\n",
    "    def process_file(file):\n",
    "        data = pd.read_excel(file, sheet_name=None, header=None)\n",
    "        frames = []\n",
    "\n",
    "        for sheet_name, df in data.items():\n",
    "            print(f\"Processing sheet: {sheet_name} from file: {file}\")  \n",
    "\n",
    "            \n",
    "            if not df.empty:\n",
    "                if file.endswith('2020.xls') and sheet_name == 'Sheet1':  \n",
    "                    df = df.iloc[2:-1]  \n",
    "                elif sheet_name == 'Sheet1':  \n",
    "                    df = df.iloc[2:]\n",
    "                elif sheet_name in ['Sheet2', 'Sheet3']:  \n",
    "                    df = df.iloc[1:] \n",
    "                    if sheet_name == 'Sheet3':\n",
    "                        df = df.iloc[:-1]  \n",
    "\n",
    "                if len(df.columns) >= 14:\n",
    "                    df.columns = [\n",
    "                        'Ticket #', 'Badge', 'Issue Date', 'IssueTime', 'Plate', 'State',\n",
    "                        'Make', 'Model', 'Violation', 'Description', 'Location', 'Meter',\n",
    "                        'Fine', 'Penalty',\n",
    "                    ]\n",
    "                    frames.append(df)\n",
    "                else:\n",
    "                    print(f\"Skipping sheet: {sheet_name} due to unexpected column count in {file}\")\n",
    "\n",
    "        if frames:\n",
    "            return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "        return pd.DataFrame() \n",
    "\n",
    "    files = [\n",
    "        'AnnArbor-TicketViolation2015.xls',\n",
    "        'AnnArbor-TicketViolation2016.xls',\n",
    "        'AnnArbor-TicketViolation2017.xls',\n",
    "        'AnnArbor-TicketViolation2018.xls',\n",
    "        'AnnArbor-TicketViolation2019.xls',\n",
    "        'AnnArbor-TicketViolation-jan2020.xls',\n",
    "    ]\n",
    "\n",
    "    all_df = []\n",
    "    for file in files:\n",
    "        df = process_file(file)\n",
    "        if not df.empty:\n",
    "            all_df.append(df)\n",
    "        else:\n",
    "            print(f\"No valid data found in file: {file}\")  \n",
    "\n",
    "    if all_df:\n",
    "        combined_df = pd.concat(all_df, ignore_index=True)\n",
    "        print(f\"Combined DataFrame shape: {combined_df.shape}\") \n",
    "        return combined_df\n",
    "    else:\n",
    "        raise ValueError(\"No valid data found in any files.\")\n",
    "\n",
    "df = load_ticket_data()\n",
    "print(f\"DataFrame Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc5804-86a7-41ec-8be3-4f8acab769d1",
   "metadata": {},
   "source": [
    "## Data Structure \n",
    "After processing, our dataset contains the following key information:\n",
    "\n",
    "Ticket information (ID, date, time)\n",
    "Vehicle details (plate, state, make, model)\n",
    "Violation specifics (type, description, location)\n",
    "Financial data (fine amount, penalties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb826d1b-8c36-472f-97b1-fe7cb0b6ee14",
   "metadata": {},
   "source": [
    "# 2. Temporal Analysis of Violations\n",
    "## Methodology\n",
    "We categorize violations across three distinct time periods to understand enforcement patterns:\n",
    "\n",
    "Morning: 3:00 AM - 11:59 AM\n",
    "Afternoon: 12:00 PM - 5:59 PM\n",
    "Evening: 6:00 PM - 2:59 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c693206c-8926-4175-b70f-f78b5002d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           12 INCHES CURB  15' FIRE HYDRAN  ABANDONED VEHIC  ACROSS LINE  \\\n",
      "Morning               174             1152              159         3049   \n",
      "Afternoon             345             2183              292         1752   \n",
      "Evening                36              613                5          282   \n",
      "\n",
      "           ACROSS MARKED SPACES  AHEAD SET/BACK  BACKED IN STALL  \\\n",
      "Morning                       0             465              483   \n",
      "Afternoon                     1             692             1078   \n",
      "Evening                       0              56                0   \n",
      "\n",
      "           BLOCK CROSSWALK  BLOCKING ALLEY  BLOCKING CRSSWA  ...  \\\n",
      "Morning                  6             113               61  ...   \n",
      "Afternoon               18             208              113  ...   \n",
      "Evening                  2              13               17  ...   \n",
      "\n",
      "           PARKING ON WALK  PKD IN INTERSECTION  PRIVATE PARK  \\\n",
      "Morning               1318                    0            69   \n",
      "Afternoon              433                    2            72   \n",
      "Evening                 64                    1             8   \n",
      "\n",
      "           PRK OVR LGL LMT  SNOW REMOVAL  STREET MAINTENA  TAXI STAND  \\\n",
      "Morning               2252            41             1506          22   \n",
      "Afternoon            36532            30              307          84   \n",
      "Evening                 22             7                0        2451   \n",
      "\n",
      "           U/M VEHICLES  UPON BRIDGE  W/I 30' TRAF CONTROL  \n",
      "Morning             101            0                     0  \n",
      "Afternoon            36            1                     5  \n",
      "Evening               4            0                     0  \n",
      "\n",
      "[3 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "def generate_descriptors(df):\n",
    "    df['IssueTime'] = df['IssueTime'].astype(str).str.zfill(4)\n",
    "    df['IssueTime'] = pd.to_numeric(df['IssueTime'], errors='coerce')\n",
    "   \n",
    "    df = df.dropna(subset=['Description'])\n",
    "    \n",
    "    def count_descriptions_in_period(df, start, end):\n",
    "        if start < end:\n",
    "            mask = (df['IssueTime'] >= start) & (df['IssueTime'] < end)\n",
    "        else:  # For evening period crossing midnight\n",
    "            mask = (df['IssueTime'] >= start) | (df['IssueTime'] < end)\n",
    "        return df.loc[mask, 'Description'].value_counts()\n",
    "    \n",
    "    morning_counts = count_descriptions_in_period(df, 300, 1200)\n",
    "    afternoon_counts = count_descriptions_in_period(df, 1200, 1800)\n",
    "    evening_counts = count_descriptions_in_period(df, 1800, 300)\n",
    "    \n",
    "    all_descriptions = list(morning_counts.index.union(afternoon_counts.index).union(evening_counts.index))\n",
    "    result = pd.DataFrame(index=['Morning', 'Afternoon', 'Evening'], columns=all_descriptions).fillna(0)\n",
    "    \n",
    "    result.loc['Morning', morning_counts.index] = morning_counts\n",
    "    result.loc['Afternoon', afternoon_counts.index] = afternoon_counts\n",
    "    result.loc['Evening', evening_counts.index] = evening_counts\n",
    "    \n",
    "    return result.fillna(0)\n",
    "\n",
    "descriptors = generate_descriptors(df)\n",
    "print(descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab8316-30be-4a58-86dd-70e37de4de1b",
   "metadata": {},
   "source": [
    "# 3. Vehicle Origin Analysis\n",
    "## New York Vehicle Profile\n",
    "We specifically analyze vehicles with New York registration to understand out-of-state parking patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50df0025-9157-4d39-a06e-bfe153035ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation-jan2020.xls\n",
      "Combined DataFrame shape: (811439, 14)\n",
      "JEEP\n"
     ]
    }
   ],
   "source": [
    "def common_car_make():\n",
    "    df = load_ticket_data()\n",
    "    \n",
    "    ny_tickets = df[df['State'] == 'NY']\n",
    "    \n",
    "    if ny_tickets.empty:\n",
    "        return \"No NY plates found\"\n",
    "\n",
    "    most_common_make = ny_tickets['Make'].value_counts().idxmax()\n",
    "    \n",
    "    return most_common_make\n",
    "\n",
    "answer = common_car_make()\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1d772-a1f8-4335-8e94-dd058ba5643f",
   "metadata": {},
   "source": [
    "# 4. Michigan License Plate Analysis\n",
    "## Pattern Recognition \n",
    "We examine different Michigan license plate formats:\n",
    "\n",
    "-Standard format (ABC1234)\n",
    "\n",
    "-Legacy format (ABC123)\n",
    "\n",
    "-Numerical prefix format (123ABC)\n",
    "\n",
    "-Custom/Vanity plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4eb5b6-750e-46ac-a4cc-d035c96d0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet2 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet3 from file: AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet1 from file: AnnArbor-TicketViolation-jan2020.xls\n",
      "Combined DataFrame shape: (811439, 14)\n",
      "Total Michigan tickets: 687047\n",
      "Count ABC1234: 467780\n",
      "Count ABC123: 42568\n",
      "Count 123ABC: 83\n",
      "Count Vanity: 176616\n",
      "{'ABC1234': 467780, 'ABC123': 42568, '123ABC': 83, 'vanity': 176616}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def fine_per_plates(df=None):\n",
    "    if df is None:\n",
    "        df = load_ticket_data() \n",
    "\n",
    "    mi_tickets = df[df['State'] == 'MI']\n",
    "    print(f\"Total Michigan tickets: {len(mi_tickets)}\") \n",
    "\n",
    "    plates = mi_tickets['Plate'].dropna().astype(str).str.strip().str.upper()\n",
    "\n",
    "\n",
    "    pattern_ABC1234 = r'^[A-Z]{3}[0-9]{4}$'  \n",
    "    pattern_ABC123 = r'^[A-Z]{3}[0-9]{3}$'   \n",
    "    pattern_123ABC = r'^[0-9]{3}[A-Z]{3}$'   \n",
    "\n",
    "    \n",
    "    count_ABC1234 = plates.str.match(pattern_ABC1234).sum()\n",
    "    count_ABC123 = plates.str.match(pattern_ABC123).sum()\n",
    "    count_123ABC = plates.str.match(pattern_123ABC).sum()\n",
    "\n",
    "    total_plates = len(plates)\n",
    "    count_vanity = total_plates - (count_ABC1234 + count_ABC123 + count_123ABC)\n",
    "  \n",
    "    count_vanity += len(mi_tickets) - len(plates)\n",
    " \n",
    "    print(f\"Count ABC1234: {count_ABC1234}\")\n",
    "    print(f\"Count ABC123: {count_ABC123}\")\n",
    "    print(f\"Count 123ABC: {count_123ABC}\")\n",
    "    print(f\"Count Vanity: {count_vanity}\")\n",
    "   \n",
    "    return {\n",
    "        \"ABC1234\": count_ABC1234,\n",
    "        \"ABC123\": count_ABC123,\n",
    "        \"123ABC\": count_123ABC,\n",
    "        \"vanity\": count_vanity\n",
    "    }\n",
    "\n",
    "result = fine_per_plates()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827a3fb-15a6-4589-b99a-dc7de22ef1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "firstTimeUsingHintbot": true,
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
